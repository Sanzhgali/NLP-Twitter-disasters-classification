{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is second notebook for Twitter Disaster Classification competition on Kaggle. In this notebook I am going to exlore data and gain some knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned datasets\n",
    "import pandas as pd\n",
    "\n",
    "train_corpused = pd.read_pickle('train_corpus.pkl')\n",
    "test_corpused = pd.read_pickle('test_corpus.pkl')\n",
    "\n",
    "train_dtm = pd.read_pickle('train_dtm.pkl')\n",
    "test_dtm = pd.read_pickle('test_dtm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>human</th>\n",
       "      <th>nature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>people receive wildfires evacuation orders in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  target  human  \\\n",
       "0   1  our deeds are the reason of this earthquake ma...       1    0.0   \n",
       "1   4              forest fire near la ronge sask canada       1    0.0   \n",
       "2   5  all residents asked to shelter in place are be...       1    0.0   \n",
       "3   6  people receive wildfires evacuation orders in ...       1    0.0   \n",
       "4   7  just got sent this photo from ruby alaska as s...       1    0.0   \n",
       "\n",
       "   nature  \n",
       "0     1.0  \n",
       "1     1.0  \n",
       "2     1.0  \n",
       "3     1.0  \n",
       "4     1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpused.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to look at the:\n",
    "    1. Median text length comparison between real disasters and fakes\n",
    "    2. Most common words in these two groups\n",
    "    3. Difference in numbers for human_related and nature_related disasters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aaaaaaallll</th>\n",
       "      <th>aaaaaand</th>\n",
       "      <th>aaarrrgghhh</th>\n",
       "      <th>aaceorg</th>\n",
       "      <th>aampb</th>\n",
       "      <th>aampw</th>\n",
       "      <th>aan</th>\n",
       "      <th>aannnnd</th>\n",
       "      <th>...</th>\n",
       "      <th>zonesthank</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zouma</th>\n",
       "      <th>zourryart</th>\n",
       "      <th>zrnf</th>\n",
       "      <th>zss</th>\n",
       "      <th>zumiez</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zxathetis</th>\n",
       "      <th>zzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows Ã— 15993 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aa  aaaa  aaaaaaallll  aaaaaand  aaarrrgghhh  aaceorg  aampb  aampw  \\\n",
       "0      0     0            0         0            0        0      0      0   \n",
       "1      0     0            0         0            0        0      0      0   \n",
       "2      0     0            0         0            0        0      0      0   \n",
       "3      0     0            0         0            0        0      0      0   \n",
       "4      0     0            0         0            0        0      0      0   \n",
       "...   ..   ...          ...       ...          ...      ...    ...    ...   \n",
       "7608   0     0            0         0            0        0      0      0   \n",
       "7609   0     0            0         0            0        0      0      0   \n",
       "7610   0     0            0         0            0        0      0      0   \n",
       "7611   0     0            0         0            0        0      0      0   \n",
       "7612   0     0            0         0            0        0      0      0   \n",
       "\n",
       "      aan  aannnnd  ...  zonesthank  zoom  zouma  zourryart  zrnf  zss  \\\n",
       "0       0        0  ...           0     0      0          0     0    0   \n",
       "1       0        0  ...           0     0      0          0     0    0   \n",
       "2       0        0  ...           0     0      0          0     0    0   \n",
       "3       0        0  ...           0     0      0          0     0    0   \n",
       "4       0        0  ...           0     0      0          0     0    0   \n",
       "...   ...      ...  ...         ...   ...    ...        ...   ...  ...   \n",
       "7608    0        0  ...           0     0      0          0     0    0   \n",
       "7609    0        0  ...           0     0      0          0     0    0   \n",
       "7610    0        0  ...           0     0      0          0     0    0   \n",
       "7611    0        0  ...           0     0      0          0     0    0   \n",
       "7612    0        0  ...           0     0      0          0     0    0   \n",
       "\n",
       "      zumiez  zurich  zxathetis  zzzz  \n",
       "0          0       0          0     0  \n",
       "1          0       0          0     0  \n",
       "2          0       0          0     0  \n",
       "3          0       0          0     0  \n",
       "4          0       0          0     0  \n",
       "...      ...     ...        ...   ...  \n",
       "7608       0       0          0     0  \n",
       "7609       0       0          0     0  \n",
       "7610       0       0          0     0  \n",
       "7611       0       0          0     0  \n",
       "7612       0       0          0     0  \n",
       "\n",
       "[7613 rows x 15993 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median number of unique words used in real disasters and fakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first let's take indices for real and fake tweets\n",
    "\n",
    "real_tweets = train_corpused.loc[train_corpused['target'] == 1, 'id']\n",
    "\n",
    "fake_tweets = train_corpused.loc[train_corpused['target'] == 0, 'id']\n",
    "\n",
    "# we already can notice that fake ones are occured more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_text = train_dtm.loc[train_dtm['id'].isin(real_tweets), :]\n",
    "\n",
    "fake_text = train_dtm.loc[train_dtm['id'].isin(fake_tweets), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11324"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after that, let's take sum by columns(unique words) and see their difference\n",
    "\n",
    "words_count_real = real_text.sum(axis = 0)\n",
    "words_count_fake = fake_text.sum(axis = 0)\n",
    "\n",
    "# Unique words (columns) used except id column\n",
    "unique_words_used_real = len(words_count_real[words_count_real > 0]) - 1\n",
    "unique_words_used_fake = len(words_count_fake[words_count_fake > 0]) - 1\n",
    "\n",
    "unique_words_used_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "sns.barplot([unique_words_used_fake, unique_words_used_real], ['Fake', 'Real'])\n",
    "plt.xlabel('Number of unique words used')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result: we can see here Fake tweets have generally more unique words used, but this is explained with amount of fake tweets which is bigger that real ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Used words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already have some sort of counter, so let's sort them in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the top 30\n",
    "top_30_real = words_count_real.sort_values(ascending=False)[:30]\n",
    "top_30_fake = words_count_fake.sort_values(ascending=False)[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_30_fake = top_30_fake.drop('id')\n",
    "top_30_real = top_30_real.drop('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check what words are now in top 30 using cloud of words, then if we find meaningless we will drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "# Now I will create plot_wordcloud function which I will be able to use multiple times by just calling\n",
    "\n",
    "def plot_wordcloud(series): # It will take pd.Series as input\n",
    "\n",
    "    plt.figure(figsize=(12, 8), dpi=100)\n",
    "    wordcloud = WordCloud(max_font_size=150, max_words=100, colormap=\"Dark2\", background_color=\"white\").generate(str(series.index.values))\n",
    "    plt.figure()\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.close()\n",
    "    \n",
    "plot_wordcloud(top_30_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(top_30_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here huge difference between most_common words in fake and real disaster tweets. Fake ones like: im, just, think, love, time. Words that are useless to describe disaster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real ones are less selfish and are like: news, disaster, accident, attack, suicide, police. Full of Information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's look at the difference between human-related and nature-related disasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take ID \n",
    "human_related = train_corpused.loc[train_corpused['human'] == 1, 'id']\n",
    "nature_related = train_corpused.loc[train_corpused['nature'] == 1, 'id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Amount of nature related tweets: {nature_related.shape}, and human-related: {human_related.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can actually see that there more tweets about human-made or human-related disasters nearly double times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_related.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create another function that will take dataframe, and list of id as input; filters by id; sums by each column; grabs first 30 words;\n",
    "# and plots wordcloud\n",
    "\n",
    "def automatically_plot(df, id_list):\n",
    "    filtered = df[df['id'].isin(id_list)]\n",
    "    filtered = filtered.drop('id', axis = 1)\n",
    "    \n",
    "    words_acc = filtered.sum(axis = 0)\n",
    "    \n",
    "    top_30 = words_acc.sort_values(ascending = False)[:30]\n",
    "    \n",
    "    plot_wordcloud(top_30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automatically_plot(train_dtm, human_related.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automatically_plot(train_dtm, nature_related.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is hard to gain some knowledge from this wordclouds because there many meaningless words in both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, I want to see distribution and correlation between real-fake and nature-human related types of tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will have 4 different sets: real disasters that are human based and nature based; fake tweets that are human and nature based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create function for this\n",
    "# Input will be a corpused and date-term matrix for both train and test sets\n",
    "\n",
    "# The thing I am trying to do is put into function all things above just to avoid doing things manually again next time \n",
    "# for other project or for another purpose\n",
    "\n",
    "def distributions_plot(df_dtm, real_id, nature_id):\n",
    "    \n",
    "    real_nature = len(df_dtm[ (df_dtm['id'].isin(real_id)) & (df_dtm['id'].isin(nature_id)) ])\n",
    "    \n",
    "    real_human = len(df_dtm[ (df_dtm['id'].isin(real_id)) & ~(df_dtm['id'].isin(nature_id)) ])\n",
    "    \n",
    "    fake_nature = len(df_dtm[ ~(df_dtm['id'].isin(real_id)) & (df_dtm['id'].isin(nature_id)) ])\n",
    "    \n",
    "    fake_human = len(df_dtm[ ~(df_dtm['id'].isin(real_id)) & ~(df_dtm['id'].isin(nature_id)) ])\n",
    "    \n",
    "    \n",
    "    \n",
    "    bars = range(2)\n",
    "    width = 0.2\n",
    "    \n",
    "    nature =  [real_nature, real_human]\n",
    "    human = [fake_nature, fake_human]\n",
    "    \n",
    "    print(nature)\n",
    "    print(human)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6), dpi = 100)\n",
    "    \n",
    "    p1 = plt.bar(bars,nature)\n",
    "    p2 = plt.bar(bars, human, bottom = nature)\n",
    "    \n",
    "    plt.ylabel('Amount of tweets')\n",
    "    plt.title('Tweets by category and realness')\n",
    "    \n",
    "    plt.xticks(bars, ('Human', 'Nature'))\n",
    "    plt.legend((p1[0], p2[0]), ('Real', 'Fake'), loc = 'upper right')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "distributions_plot(train_dtm, real_tweets, human_related)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I want to create a function that takes dataframe and removes columns(words) that are occured less than 10 times\n",
    "\n",
    "def remove_less_occured(train_df, test_df):\n",
    "    #train_df.drop('id', axis = 1, inplace = True)\n",
    "    words_occ = train_df.sum(axis = 0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    to_remove = list(words_occ[words_occ < 3].index)\n",
    "    train_df = train_df.drop(to_remove, axis = 1)\n",
    "    \n",
    "    \n",
    "    test_df = test_df.drop(to_remove, axis = 1)\n",
    "    \n",
    "\n",
    "    return (train_df, test_df)\n",
    "\n",
    "\n",
    "\n",
    "train_dtm, test_dtm = remove_less_occured(train_dtm, test_dtm)\n",
    "\n",
    "train_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dtm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now from over 15000 columns we removed 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's save data for next step\n",
    "\n",
    "test_dtm.to_pickle('test_dtm_reduced.pkl')\n",
    "\n",
    "train_dtm.to_pickle('train_dtm_reduced.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
